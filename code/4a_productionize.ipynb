{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b6a682-0056-4d22-8fc6-babef4d203bb",
   "metadata": {},
   "source": [
    "# Productionize\n",
    "\n",
    "In this notebook, we will develop the production code for a pipeline to acquire, detect, and forecast vehicle traffic counts from traffic images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63539870-d306-4562-a860-28395d58a827",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c80e29f-e2e1-46de-b18d-9f911932672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "\n",
    "import ast\n",
    "import requests\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import datetime \n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# import glob\n",
    "# import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988624a9-63e5-428a-a57a-78bdd95e931c",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329a4f00-4e2f-4aca-a8f4-49a58123919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTS\n",
    "\n",
    "# database locations\n",
    "DATABASE_PATH_ROOT = '../production/database/'\n",
    "LINKS_DB_FILENAME = 'links_db.csv'\n",
    "IMG_PATH_DB_FILENAME = 'img_path_db.csv'\n",
    "VEHICLE_COUNT_DB_FILENAME = 'vehicle_count_db.csv'\n",
    "PREDICTIONS_LINK_DB_FILENAME = 'prediction_link_db.csv'\n",
    "\n",
    "# image download variables\n",
    "IMG_LINK_PREFIX ='https://images.data.gov.sg/api/traffic-images/'\n",
    "IMAGES_PATH_ROOT =  '../production/images/'\n",
    "\n",
    "# image processing variables\n",
    "YOLO_DNN_WEIGHTS_PATH = \"../dnn_model/yolov7.weights\"\n",
    "YOLO_DNN_CFG_PATH = \"../dnn_model/yolov7.cfg\"\n",
    "IMAGE_MASK_PATH_ROOT = '../production/image_masks/'\n",
    "OUTPUT_IMAGES_PATH_ROOT =  '../production/processed_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074fdb26-8f1b-4b25-b8dc-ef0deff3c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LIST OF IMPROVEMENTS\n",
    "# - use blaze to load up data faster\n",
    "# - make a bulk download and bulk inference module to catch up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae9ac1-d2fb-4891-8bde-6c7a51b34eec",
   "metadata": {},
   "source": [
    "# Links Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a43bcb9-d52d-4f13-8c0e-d95be48aa6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LINKS DOWNLOADS\n",
    "\n",
    "def call_lta_api(datetime_call):\n",
    "    '''\n",
    "    This function calls the LTA traffic images API based on a certain datetime and returns a datafrane row with the time as index and camera_ids as column\n",
    "    '''\n",
    "\n",
    "    # getting the api call\n",
    "    api = 'https://api.data.gov.sg/v1/transport/traffic-images?date_time='+ \\\n",
    "    datetime_call.strftime(\"%Y-%m-%d\") + \"T\" + datetime_call.strftime(\"%H\") + \"%3A\" + datetime_call.strftime(\"%M\") + \"%3A00\"\n",
    "    \n",
    "    # reading the camera data from data.gov.sg\n",
    "    list_of_camera_info = ast.literal_eval(requests.get(api).content.decode(\"utf-8\"))[\"items\"][0][\"cameras\"]\n",
    "\n",
    "    # instantiating a dataframe to contain the output\n",
    "    output = pd.DataFrame()\n",
    "    \n",
    "    for item in list_of_camera_info: # iterating through each item in the list\n",
    "        item_series = pd.Series(item['image'].replace(IMG_LINK_PREFIX,''), # getting the image names and removing the IMG_LINK_PREFIX to save space\n",
    "                                index=[(pd.to_datetime(item['timestamp']) # setting the index as the timestamp (all series will be concatenated using this index)\n",
    "                                       .replace(tzinfo=None))], # removing the timezone information\n",
    "                                name=item['camera_id']) # setting the name/column_name as the camera ID for storage in database\n",
    "        output = pd.concat([output, item_series],axis=1) # concatenating\n",
    "    \n",
    "    # dropping these cameras as they have been shown to have problems with having different polling time compared to the other cams\n",
    "    # output = output.drop(['1001','1002','1003','1004','1005','1006'],axis=1)\n",
    "    \n",
    "    # checking if there are any asynchronous camera links (i.e.: cameras link occur at more than one timestamp, resulting in multiple rows/timestamps for one call)\n",
    "    is_asynchronous = output.isna().sum().sum() > 0\n",
    "    \n",
    "    if is_asynchronous:\n",
    "        output = (output.fillna(method='bfill').fillna(method='ffill'). # fill all rows (timecode) in each column (camera) with the non-null_value in that column\n",
    "                  sort_index(ascending=False).iloc[[0]]) # then condense the whole dataframe to one row by selecting the latest timecode\n",
    "    \n",
    "    # returning the output\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def download_links(datetime_call):\n",
    "    '''\n",
    "    This function takes a datetime object and obtains the links from the LTA API based on the datetime\n",
    "    It will then save the links in the links_db\n",
    "    The function will first check if the called datetime is already available in the links_db, if so, it will skip the download\n",
    "    \n",
    "    \n",
    "    ### NOTES:\n",
    "    This function loads up the entire links_db during its function call, a more efficient system would involve a SQL database, which will be implemented in the future\n",
    "    \n",
    "    Ideally, this function will only be called sequentially (i.e.: only called once every 5 minutes, and no historical calls), this is to make sure that the links_db is always sorted\n",
    "    However, for simplicity purposes, the links_db dataframe will be sorted at the end of the function, this is highly inefficient as links_db gets larger\n",
    "    When deployed using the scheduler, this sorting step will be skipped\n",
    "    '''\n",
    "    \n",
    "    # loads the links database from csv\n",
    "    links_db_df = pd.read_csv(DATABASE_PATH_ROOT+LINKS_DB_FILENAME,index_col=0)\n",
    "    links_db_df.index = pd.to_datetime(links_db_df.index) # converting the index to datetime\n",
    "    \n",
    "    # checking if timestamp is already available in the links_db\n",
    "    df_is_empty = links_db_df.loc[datetime_call-timedelta(minutes=8):datetime_call].empty\n",
    "    \n",
    "    # IF NOT AVAIL\n",
    "    if df_is_empty:\n",
    "\n",
    "        # downloads the list of links from the API and adding it to the end of the dataframe\n",
    "        new_links_df_row = call_lta_api(datetime_call) # downloads links using the function to generate a new row\n",
    "        links_db_df = pd.concat([links_db_df,new_links_df_row],axis=0) # adding the row to the bottom of the links_db dataframe\n",
    "\n",
    "        # sorting the dataframe\n",
    "        ## WILL BE SKIPPED FOR WHEN USING THE SCHEDULER\n",
    "        links_db_df = links_db_df.sort_index()\n",
    "\n",
    "        # saves the dataframe to the links_db.csv\n",
    "        links_db_df.to_csv(DATABASE_PATH_ROOT+LINKS_DB_FILENAME)\n",
    "    \n",
    "    # additionally returns the updated links_db_df (for when this function is called to update the database)\n",
    "    return links_db_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd3fa3-ac8b-4352-ad00-e2fdab079b97",
   "metadata": {},
   "source": [
    "# Images Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d35d31-bb2e-42b9-aae6-e0f675d42478",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMAGES DOWNLOADS\n",
    "\n",
    "def get_image_link(cam_id_call,datetime_call):\n",
    "    '''\n",
    "    This function takes the camera_id and date_time to be called and outputs the download link and download_path for the image file\n",
    "    The download link is obtained from the links_db, if no link is present in the links_db (because it's not been downloaded yet), it will attempt to download the links\n",
    "    \n",
    "    ### NOTES:\n",
    "    This function loads up the entire links_db during its function call, a more efficient system would involve a SQL database, which will be implemented in the future\n",
    "    '''\n",
    "    # LOADING DATABASE\n",
    "    # loads the links database from csv\n",
    "    links_db_df = pd.read_csv(DATABASE_PATH_ROOT+LINKS_DB_FILENAME,index_col=0)\n",
    "    links_db_df.index = pd.to_datetime(links_db_df.index) # converting the index to datetime\n",
    "    \n",
    "    cam_id_call = str(cam_id_call)\n",
    "    \n",
    "    # CHECKING (AND DOWNLOADING) LINKS\n",
    "    # checks the availability of the link\n",
    "    link_is_empty = links_db_df.loc[datetime_call-timedelta(minutes=8):datetime_call,cam_id_call].empty\n",
    "\n",
    "    # downloads the links if the link is empty\n",
    "    if link_is_empty:\n",
    "        links_db_df = download_links(datetime_call=datetime_call)\n",
    "    \n",
    "    # GETTING THE IMAGE LINK\n",
    "    # obtain the image link from the links_db\n",
    "    img_link = links_db_df.loc[datetime_call-timedelta(minutes=8):datetime_call,cam_id_call][0]\n",
    "\n",
    "    # ERROR CATCHING IF NO DOWNLOAD LINK AVAILABLE\n",
    "    move_back_counter = 1\n",
    "    while type(img_link)!=str:\n",
    "        datetime_call_new = datetime_call-timedelta(minutes=5*move_back_counter)\n",
    "        img_link = links_db_df.loc[datetime_call_new-timedelta(minutes=8):datetime_call_new,cam_id_call][0]\n",
    "        move_back_counter += 1\n",
    "    \n",
    "    # GETTING THE IMAGE FILENAME AND PATH\n",
    "    # obtain the image timestamp from the links_db\n",
    "    img_timestamp = links_db_df.loc[datetime_call-timedelta(minutes=8):datetime_call,cam_id_call].index[0]\n",
    "    \n",
    "    # decide the name of the image file based on the camera_id and time\n",
    "    img_filename = (\"-\".join([str(cam_id_call), # get the camera_id\n",
    "                              img_timestamp.strftime(\"%Y_%m_%d_%H_%M\"), # get the timestamp\n",
    "                             ]) # combine the cam_id and timestamp with a dash '-'\n",
    "                    + '.jpg') # add .jpg as filetype\n",
    "    \n",
    "    # decide the path of the image file based on the camera_id and time\n",
    "    img_path = (\"/\".join([img_timestamp.strftime(\"%Y_%m_%d\"), # get the date\n",
    "                          str(cam_id_call), # get the camera_id\n",
    "                             ]) # combine the cam_id and timestamp with a slash '/' (indicating folder structure)\n",
    "               +'/') # add / for final folder path\n",
    "    \n",
    "    return img_link, img_filename, img_path\n",
    "\n",
    "\n",
    "\n",
    "def download_image_from_link(img_link, img_filename, img_path):\n",
    "    '''\n",
    "    This function downloads the image from the data.gov api based on its link and puts it in the proper filepath and filename\n",
    "    '''\n",
    "    \n",
    "    # getting full image link\n",
    "    img_link = IMG_LINK_PREFIX+img_link\n",
    "    \n",
    "    # getting full image download path\n",
    "    img_path = IMAGES_PATH_ROOT+img_path\n",
    "    \n",
    "    # getting the file from the url\n",
    "    r = requests.get(img_link, allow_redirects=True)\n",
    "    \n",
    "    # create folder if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(img_path), exist_ok=True)\n",
    "\n",
    "    # combining the path and filename to get the full path\n",
    "    full_path = img_path + '/' + img_filename \n",
    "    \n",
    "    # writing the file to the path\n",
    "    with open(full_path, 'wb') as f: \n",
    "        f.write(r.content)\n",
    "        \n",
    "        \n",
    "def image_downloader(cam_id_call,datetime_call):\n",
    "    '''\n",
    "    This function takes a the cam_id and timestamp and attempts to download the traffic images using links from links_db and save the path to img_path_db\n",
    "    The function will first check if the called datetime and cam_id is already available in the img_path_db, if so, it will skip the download\n",
    "    \n",
    "    \n",
    "    ### NOTES:\n",
    "    This function loads up the entire img_path_db during its function call, a more efficient system would involve a SQL database, which will be implemented in the future\n",
    "    \n",
    "    Ideally, this function will only be called sequentially (i.e.: only called once every 5 minutes, and no historical calls), this is to make sure that the img_path_db is always sorted\n",
    "    However, for simplicity purposes, the img_path_db dataframe will be sorted at the end of the function, this is highly inefficient as links_db gets larger\n",
    "    When deployed using the scheduler, this sorting step will be skipped\n",
    "    '''\n",
    "    # LOADING DATABASE\n",
    "    # loads the img_path database from csv\n",
    "    img_path_db_df = pd.read_csv(DATABASE_PATH_ROOT+IMG_PATH_DB_FILENAME,index_col=0)\n",
    "    img_path_db_df.index = pd.to_datetime(img_path_db_df.index) # converting the index to datetime\n",
    "    \n",
    "    \n",
    "    # CHECKING CAMERA ID\n",
    "    # converts the cam_id_call to a string for indexing\n",
    "    cam_id_call = str(cam_id_call)\n",
    "    \n",
    "    # checks if cam_id_call is part of the available camera\n",
    "    if cam_id_call not in (img_path_db_df.columns):\n",
    "        raise Exception(\"No such camera ID\") # throws error if there is no such camera ID\n",
    "    \n",
    "    \n",
    "    # CHECKING IF IMAGE IS ALREADY PRESENT FROM THE img_path_db\n",
    "    is_img_path_absent = img_path_db_df.loc[datetime_call-timedelta(minutes=8):datetime_call,str(cam_id_call)].dropna().empty\n",
    "    \n",
    "    # skipping out of this function if the img_path is NOT absent (i.e.: if image is already downloaded)\n",
    "    if not is_img_path_absent:\n",
    "        return None\n",
    "    \n",
    "    # GETTING THE IMAGE FROM THE API AND SAVING THE PATH TO img_path_db\n",
    "    # getting the img link, filename, and path from the get_image link function\n",
    "    img_link, img_filename, img_path = get_image_link(cam_id_call=cam_id_call,datetime_call=datetime_call)\n",
    "    \n",
    "    # downloading the image\n",
    "    download_image_from_link(img_link, img_filename, img_path)\n",
    "    \n",
    "    # getting the image timestamp from the filename\n",
    "    yr,mo,dy,hr,mn = img_filename[5:9], img_filename[10:12], img_filename[13:15], img_filename[16:18], img_filename[19:21] # getting the datetime stamp\n",
    "    yr,mo,dy,hr,mn = [int(x) for x in [yr,mo,dy,hr,mn]] # converting the datetime stamp to integers\n",
    "    img_timestamp = dt(yr,mo,dy,hr,mn)\n",
    "    \n",
    "    # getting the image full path\n",
    "    img_full_path = img_path + img_filename\n",
    "    \n",
    "    # adding the full path to the img_path_db\n",
    "    img_path_db_df.loc[img_timestamp,str(cam_id_call)] = img_full_path\n",
    "    \n",
    "    # sorting the dataframe\n",
    "    ## WILL BE SKIPPED FOR WHEN USING THE SCHEDULER\n",
    "    img_path_db_df = img_path_db_df.sort_index()\n",
    "    \n",
    "    # saving the img_path_db\n",
    "    img_path_db_df.to_csv(DATABASE_PATH_ROOT+IMG_PATH_DB_FILENAME)\n",
    "    \n",
    "    # additionally returns the updated img_path_db_df (for when this function is called to update the database)\n",
    "    return img_path_db_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbac8d3c-ecf1-4949-85ed-f0f2fc060d52",
   "metadata": {},
   "source": [
    "# Vehicle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "383a1e3a-4b49-4447-a22d-f8b7bf757a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VEHICLE COUNTER\n",
    "\n",
    "class VehicleDetector:\n",
    "    '''\n",
    "    This class is used to contain the vehicle detector using the pretrained YOLOv7\n",
    "    Using self.class_allowed, the user can filter which types of objects (or vehicles) that is detected\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        # initialize the class by loading the pre-trained model and setting the allowable classes\n",
    "        \n",
    "        # Load DNN from pre-trained model\n",
    "        net = cv2.dnn.readNet(YOLO_DNN_WEIGHTS_PATH, YOLO_DNN_CFG_PATH)\n",
    "        \n",
    "        # setup model and parameters\n",
    "        self.model = cv2.dnn_DetectionModel(net)\n",
    "        self.model.setNmsAcrossClasses(True) # setting so that the NMS applies across different classes\n",
    "        self.model.setInputParams(size=(832, 832), scale=1 / 255)\n",
    "\n",
    "        # Allow classes containing Vehicles only\n",
    "        self.classes_allowed = [1, 2, 3, 5, 7] # classes are same as COCO class, but SUBTRACT BY ONE, \n",
    "        # i.e.: {1:'bicycle', 2:'car',3:'motorcycle', 5:'bus', 7:'truck'}\n",
    "\n",
    "    def get_bounding_box(self, img):\n",
    "        '''\n",
    "        This function takes an image and returns the bounding boxes of vehicles detected inside\n",
    "        '''\n",
    "        \n",
    "        # Create a list to contain all detected instance of vehicles\n",
    "        vehicle_boxes = []\n",
    "        \n",
    "        # detect if a none-type image is loaded (could be because of image error) and returns an error, this will be caught later in the main detection function\n",
    "        if img is None:\n",
    "            vehicle_boxes = ['image_error!']\n",
    "            return vehicle_boxes\n",
    "        \n",
    "        # Detect Objects\n",
    "        class_ids, scores, boxes = self.model.detect(img, \n",
    "                                                     nmsThreshold=0.5, # NMS threshold --> higher = more close boxes together\n",
    "                                                     confThreshold=0.15)\n",
    "        \n",
    "        # looping through each object detected\n",
    "        for class_id, score, box in zip(class_ids, scores, boxes):\n",
    "            # if the object is within the allowed class, then add the item in the vehicle_boxes list\n",
    "            if class_id in self.classes_allowed:\n",
    "                vehicle_boxes.append({'class_id':class_id+1,\n",
    "                                      'score':score,\n",
    "                                      'box':box})\n",
    "                \n",
    "        return vehicle_boxes\n",
    "    \n",
    "    \n",
    "    def preprocess(self, img, mask_path=None): \n",
    "        '''\n",
    "        This is a helper function to preprocess the image given a mask\n",
    "        In this particular instance, no further preprocessing was implemented,\n",
    "        but in theory, sharpening or contrast correction could be added here to help the image detection algorithm\n",
    "        '''\n",
    "        # load mask from directory\n",
    "        if mask_path==None: # if no maks is specified, then generate a white mask (i.e.: everything will pass)\n",
    "            mask = np.zeros((1080,1920),dtype=np.uint8)\n",
    "            mask[:] = 255\n",
    "\n",
    "        else: # if a mask is specified, then use the pre-defined mask\n",
    "            mask = cv2.imread(mask_path)\n",
    "            mask = cv2.cvtColor(mask,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # masking image using the pre-defined mask\n",
    "        img = cv2.bitwise_or(img,img,mask=mask)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def process_image(self, img, mask_path=None):\n",
    "        '''\n",
    "        This function returns the processed image and total vehicle count given an image and a mask_path (used for masking the camera to only the ROI)\n",
    "        There are various error catching function here which will raise a warning if the function is unable to conduct the preprocessing or detection\n",
    "        '''\n",
    "        # INITIALIZATION\n",
    "        # define vehicle dictionary\n",
    "        object_dictionary = {2:'bicycle',3:'car',4:'motorcycle',6:'bus',8:'truck'}\n",
    "\n",
    "        # print error if image failed to load\n",
    "        if img is None:\n",
    "            print(f'error in loading image {img_filename}')\n",
    "\n",
    "        # create a clean copy (without masking or preprocessing) to be outputed later with the bounding boxes\n",
    "        output_img = img.copy() \n",
    "\n",
    "        # PREPROCESSING\n",
    "        # attempt to preprocess and mask the image\n",
    "        try:\n",
    "            img = self.preprocess(img=img,\n",
    "                                  mask_path=mask_path)\n",
    "        # if masking fails (due to absence of mask or other things) use the original image\n",
    "        except:\n",
    "            img = output_img\n",
    "            warnings.warn(\"Warning: Image Preprocessing Error\")\n",
    "            \n",
    "        # DETECTING VEHICLES\n",
    "        # use the get_bounding_box function to return the vehicle boxes\n",
    "        vehicle_boxes = self.get_bounding_box(img)\n",
    "\n",
    "        # error catching for detection error\n",
    "        if vehicle_boxes == ['image_error!']:\n",
    "            warnings.warn(\"Warning: Image Detection Error\")\n",
    "\n",
    "        # counting number of vehicles\n",
    "        vehicle_count = len(vehicle_boxes)\n",
    "\n",
    "        # DRAWING BOUNDING BOXES\n",
    "        for vehicle_box in vehicle_boxes:\n",
    "            x, y, w, h = vehicle_box['box']\n",
    "\n",
    "            cv2.rectangle(output_img, (x, y), (x + w, y + h), (25, 0, 180), 3)\n",
    "            cv2.putText(output_img, f\"{object_dictionary[vehicle_box['class_id']]} | {vehicle_box['score']:.2f}\", (x, y + h), 0, 1, (255, 255, 255), 1)\n",
    "\n",
    "        # ADDING TEXT WITH VEHICLE COUNT\n",
    "        cv2.putText(output_img, \"Vehicle count: \" + str(vehicle_count), (20, 50), 0, 2, (100, 200, 0), 3)\n",
    "\n",
    "        return output_img, vehicle_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1db6a0-64bb-40e4-a373-ca4c42d8c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vehicle_count(cam_id_call, datetime_call):\n",
    "    '''\n",
    "    This function takes in the camera_id and datetime and runs a vehicle detection on the corresponding image\n",
    "    If the image is not yet downloaded, the function will attempt to download the image\n",
    "    '''\n",
    "    # LOADING DATABASE\n",
    "    # loads the img_path database from csv\n",
    "    img_path_db_df = pd.read_csv(DATABASE_PATH_ROOT+IMG_PATH_DB_FILENAME,index_col=0)\n",
    "    img_path_db_df.index = pd.to_datetime(img_path_db_df.index) # converting the index to datetime\n",
    "    \n",
    "    # loads the img_path database from csv\n",
    "    vehicle_count_db_df = pd.read_csv(DATABASE_PATH_ROOT+VEHICLE_COUNT_DB_FILENAME,index_col=0)\n",
    "    vehicle_count_db_df.index = pd.to_datetime(vehicle_count_db_df.index) # converting the index to datetime\n",
    "    \n",
    "    \n",
    "    # CHECKING CAMERA ID\n",
    "    # converts the cam_id_call to a string for indexing\n",
    "    cam_id_call = str(cam_id_call)\n",
    "    \n",
    "    # checks if cam_id_call is part of the available camera\n",
    "    if cam_id_call not in (img_path_db_df.columns):\n",
    "        raise Exception(\"No such camera ID\") # throws error if there is no such camera ID\n",
    "    \n",
    "    \n",
    "    # CHECKING IF IMAGE HAS BEEN DOWNLOADED FROM THE img_path_db\n",
    "    is_img_path_absent = img_path_db_df.loc[datetime_call-timedelta(minutes=8):datetime_call,str(cam_id_call)].dropna().empty\n",
    "    \n",
    "    # downloads the image if the image is absent\n",
    "    if is_img_path_absent: \n",
    "        img_path_db_df = image_downloader(cam_id_call=cam_id_call, datetime_call=datetime_call)\n",
    "        \n",
    "        \n",
    "    # CHECKING IF IMAGE HAS BEEN PROCESSED FROM THE vehicle_count_db\n",
    "    is_vehicle_count_absent = vehicle_count_db_df.loc[datetime_call-timedelta(minutes=8):datetime_call,str(cam_id_call)].dropna().empty\n",
    "    \n",
    "    # skips the vehicle count if image has already been processed (i.e.: NOT absent)\n",
    "    if not is_vehicle_count_absent: \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    # GETTING THE IMAGE PATH FROM img_path_db\n",
    "    img_path = img_path_db_df.loc[datetime_call-timedelta(minutes=8):datetime_call,str(cam_id_call)][0]\n",
    "    \n",
    "    # getting the image timestamp from the filename\n",
    "    img_filename = os.path.basename(img_path)\n",
    "    yr,mo,dy,hr,mn = img_filename[5:9], img_filename[10:12], img_filename[13:15], img_filename[16:18], img_filename[19:21] # getting the datetime stamp\n",
    "    yr,mo,dy,hr,mn = [int(x) for x in [yr,mo,dy,hr,mn]] # converting the datetime stamp to integers\n",
    "    img_timestamp = dt(yr,mo,dy,hr,mn)\n",
    "    \n",
    "    # VEHICLE DETECTION\n",
    "    # Load Veichle Detector class\n",
    "    vd = VehicleDetector()\n",
    "\n",
    "    # read the image from path\n",
    "    img = cv2.imread(IMAGES_PATH_ROOT+img_path)\n",
    "    \n",
    "    # obtain mask_path from cam_id\n",
    "    mask_path = IMAGE_MASK_PATH_ROOT+str(cam_id_call)+'.jpg'\n",
    "    \n",
    "    # getting the processed image and vehicle count from the process_image function\n",
    "    output_img, vehicle_count = vd.process_image(img=img,mask_path=mask_path)\n",
    "    \n",
    "    # saving processed image\n",
    "    img_path_out = OUTPUT_IMAGES_PATH_ROOT + img_path # getting the output image path\n",
    "    os.makedirs(os.path.dirname(img_path_out), exist_ok=True) # create folder if doesn't exist\n",
    "    cv2.imwrite(img_path_out, output_img) # writing the image to the output folder\n",
    "    \n",
    "    # SAVING VEHICLE_COUNT TO DATABASE\n",
    "    # adding the vehicle count to the img_path_db\n",
    "    vehicle_count_db_df.loc[img_timestamp,str(cam_id_call)] = int(vehicle_count)\n",
    "    \n",
    "    # sorting the dataframe\n",
    "    ## WILL BE SKIPPED FOR WHEN USING THE SCHEDULER\n",
    "    vehicle_count_db_df = vehicle_count_db_df.sort_index()\n",
    "    \n",
    "    # saving the img_path_db\n",
    "    vehicle_count_db_df.to_csv(DATABASE_PATH_ROOT+VEHICLE_COUNT_DB_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf5a1f6-9672-46bd-a301-ba4ed2317fd2",
   "metadata": {},
   "source": [
    "# Catch Up Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97fd0cfa-256b-4a27-b79f-6a7994cd18bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catch_up_count(dt_start=dt.now().replace(hour=0,minute=0), dt_end=dt.now(), dt_resolution_mins=10):\n",
    "    '''\n",
    "    This function is used to catch up the vehicle counts from the staring to end datetime, and the predetermined resolution\n",
    "    '''\n",
    "    cam_id_list = [1702,2706,4708,4702,6710,6714,7793]\n",
    "    # getting the datetime list from the datetime start and end\n",
    "    num_of_observations = round((dt_end-dt_start)/timedelta(minutes=dt_resolution_mins)) # getting the number of observations\n",
    "    dt_list = [dt_end - timedelta(minutes=x*dt_resolution_mins) for x in range(num_of_observations)][::-1] # making the datetime list\n",
    "\n",
    "    # creating all the combos of datetime and camera_id\n",
    "    combo_list = list(itertools.product(dt_list,cam_id_list))\n",
    "    combo_list_pbar = tqdm(combo_list) # converting to a tqdm to display progress bar\n",
    "\n",
    "    # iterating through all the combo of datetime and camera_id, and doing the vehicle count on those combos\n",
    "    for dt_call, cam_id in combo_list_pbar:\n",
    "        try: \n",
    "            vehicle_count(cam_id_call=cam_id, datetime_call=dt_call)\n",
    "        except Exception as e: \n",
    "            print(f'error in processing {cam_id} at {dt_call.strftime(\"%Y-%m-%d %H-%M\")} | {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9e1cfcd-860d-4ee4-8a7f-48a0bb6a1e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b260b596908c43c98e6b29968dc75e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/595 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "catch_up_count(dt_start=dt.now().replace(hour=0,minute=0), \n",
    "               dt_end=dt.now(), \n",
    "               dt_resolution_mins=10,\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b0284-3caa-4e64-8d9c-1e80f6d45ea1",
   "metadata": {},
   "source": [
    "# Constant Update Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4976486f-f035-4e95-9a5a-e06fdc2b0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import schedule\n",
    "\n",
    "def get_cam_now():\n",
    "    '''\n",
    "    This function will do a vehicle_count for all the cameras in cam_id_list at the current datetime\n",
    "    '''\n",
    "    cam_id_list = [1702,2706,4708,4702,6710,6714,7793]\n",
    "    dt_list = [dt.now()]\n",
    "    \n",
    "    print(dt.now().strftime('Getting data at %H:%M'))\n",
    "\n",
    "    combo_list = list(itertools.product(cam_id_list, dt_list))\n",
    "    combo_list_pbar = tqdm(combo_list)\n",
    "\n",
    "    for cam_id, dt_call in combo_list_pbar:\n",
    "        try: \n",
    "            vehicle_count(cam_id_call=cam_id, datetime_call=dt_call)\n",
    "            \n",
    "        except Exception as e: \n",
    "            print(f'error in processing {cam_id} at {dt_call.strftime(\"%Y-%m-%d %H:%M\")} | {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a80a2-bab6-4ba4-ad24-ce45a8c945b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data at 14:10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb5bce24f1e49f890f6afb69d4e3755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data at 14:20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e7d56ea99545fea5a96c4e89930417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data at 14:30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20c3f5d665b4c9498f25b08b7cbef57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data at 14:41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c5ad8ff96a421cbd9ddf6d8d9abbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data at 14:51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6890c2dff8644108bf96cc01183da82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data at 15:01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d1b148e9184cb39a3362ed8aa49cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data at 15:11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793cad9dee00454d9a076f348b28b70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data at 15:22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294dbe1d24494af2b5e71728b8d40784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schedule.clear()\n",
    "get_cam_now()\n",
    "schedule.every(10).minutes.do(get_cam_now)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69c6c6-b969-479c-b9a4-c96506197d9c",
   "metadata": {},
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c84a3819-38d5-4266-9b52-cb374e515446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models.forecasting.prophet_model import Prophet\n",
    "\n",
    "def generate_weekly_predictions_list(cam_id, training_start_datetime, training_end_datetime):\n",
    "    '''\n",
    "    This function generatees a weekly prediction for a particular camera, using training data of the vehicle count within the predefined training start and end datetime\n",
    "    The generated prediction is a list (with no corresponding datetime index) which contains the predicted number of vehicle per 30 minute interval, starting from midnight on Monday\n",
    "    The prediction list will be 336 long (7 x 48)\n",
    "    '''\n",
    "    # LOADING DATABASE\n",
    "    # loads the img_path database from csv\n",
    "    vehicle_count_db_df = pd.read_csv(DATABASE_PATH_ROOT+VEHICLE_COUNT_DB_FILENAME,index_col=0)\n",
    "    vehicle_count_db_df.index = pd.to_datetime(vehicle_count_db_df.index) # converting the index to datetime\n",
    "    \n",
    "     # getting the particular segment of the database for training\n",
    "    vehicle_count = vehicle_count_db_df.loc[training_start_datetime:training_end_datetime,cam_id]\n",
    "    \n",
    "    # aggregating the vehicle count data by 30 minutes\n",
    "    vehicle_count_agg = vehicle_count.groupby(pd.Grouper(freq='30Min')).aggregate(np.mean)\n",
    "    \n",
    "    \n",
    "    # DARTS MODELLING\n",
    "    # converting the vehicle count data to a Darts Timeseries object\n",
    "    vehicle_count_agg_ts = (TimeSeries.from_series(vehicle_count_agg, # selecting the total traffic_count feature from the df\n",
    "                                                   fillna_value=0, # filling the empty values with 0\n",
    "                                                  ).astype(np.float32)) # casting as float 32 to save memory and computation time\n",
    "\n",
    "    # instantiating an FB prophet model\n",
    "    prophet = Prophet(add_seasonalities=[{\n",
    "                                          'name': 'weekly-7*48',  # (name of the seasonality component),\n",
    "                                          'seasonal_periods': 7*48,  # (nr of steps composing a season),\n",
    "                                          'fourier_order': 100,  # (number of Fourier components to use),\n",
    "                                          'mode': 'additive',  # ('additive' or 'multiplicative')\n",
    "                                          },\n",
    "                                          {\n",
    "                                          'name': 'daily-1*48',  # (name of the seasonality component),\n",
    "                                          'seasonal_periods': 1*48,  # (nr of steps composing a season),\n",
    "                                          'fourier_order': 100,  # (number of Fourier components to use),\n",
    "                                          'mode': 'additive',  # ('additive' or 'multiplicative')\n",
    "                                          }])\n",
    "\n",
    "    # fitting the prophet model using the vehicle count\n",
    "    prophet.fit(vehicle_count_agg_ts)\n",
    "\n",
    "    # getting the prediction from the prophet model\n",
    "    vehicle_count_prediction = prophet.predict(n=2*7*48).pd_series()\n",
    "\n",
    "    \n",
    "    # CONVERTING PREDICTION TO LIST\n",
    "    # getting the correct starting time for the weekly prediction (which is the first midnight (00:00) on a monday)\n",
    "    \n",
    "    # getting the location of all monday midnights\n",
    "    midnight_on_monday_mask = ((vehicle_count_prediction.index.day_of_week == 0) & # filter by day of week is 0 (monday)\n",
    "                               (vehicle_count_prediction.index.time == datetime.time(0,0))) # and also filter by start of day (time = 00:00)\n",
    "\n",
    "    # getting the index timestamp of the first monday midnight\n",
    "    prediction_start_index = vehicle_count_prediction[midnight_on_monday_mask].index[0]\n",
    "\n",
    "    # filtering the prediction to a weekly prediction starting the monday midnight to sunday 23:30\n",
    "    vehicle_count_prediction_list = (vehicle_count_prediction.loc[prediction_start_index: # starting the weekly prediction from the monday midnight\n",
    "                                                                  prediction_start_index+timedelta(days=7)][:-1] # ending the prediction one week later\n",
    "                                    ).to_list() # converting it to a list\n",
    "    \n",
    "    return vehicle_count_prediction_list\n",
    "\n",
    "\n",
    "def make_weekly_predictions(cam_ids, training_start_datetime, training_end_datetime):\n",
    "    '''\n",
    "    This function uses the generate_weekly_predictions_list to make weekly predictions for the given cam_ids and training preriod\n",
    "    The function will read from the predictions database, load up the latest model, and update the models accordingly\n",
    "    '''\n",
    "    # LOADING DATABASE\n",
    "    # loads the predictions link database from csv\n",
    "    predictions_link_db_df = pd.read_csv(DATABASE_PATH_ROOT+PREDICTIONS_LINK_DB_FILENAME,index_col=0,parse_dates=True)\n",
    "\n",
    "    # getting the latest prediction file path\n",
    "    latest_prediction_file_path = predictions_link_db_df['path'].iloc[-1]\n",
    "\n",
    "    # loads the latest predictions database from csv\n",
    "    weekly_predictions_df = pd.read_csv(DATABASE_PATH_ROOT+latest_prediction_file_path,index_col=0)\n",
    "\n",
    "\n",
    "    # GENERATING PREDICTIONS\n",
    "    for cam_id in cam_ids: # looping through all the requested camera_ids\n",
    "        cam_id = str(cam_id) # converting the cam_id to a string\n",
    "        weekly_predictions_df[cam_id] = generate_weekly_predictions_list(cam_id, training_start_datetime, training_end_datetime) # generate the prediction of the cam_id and over-writing the existing predictions\n",
    "\n",
    "\n",
    "    # SAVING THE PREDICTIONS INTO THE DATABASE\n",
    "    # getting the current time without the microsecond\n",
    "    dt_now = dt.now().replace(microsecond=0)\n",
    "\n",
    "    # generating the new prediction filename\n",
    "    new_prediction_filename = 'predictions/'+dt_now.strftime('%Y%m%d_%H%M%S')+'.csv'\n",
    "\n",
    "    # saving the new prediction database to csv\n",
    "    weekly_predictions_df.to_csv(DATABASE_PATH_ROOT+new_prediction_filename)\n",
    "\n",
    "    # updating the prediction links database\n",
    "    predictions_link_db_df.loc[dt_now,'path'] = new_prediction_filename\n",
    "    predictions_link_db_df.loc[dt_now,'cam_ids_updated'] = str(cam_ids)\n",
    "    predictions_link_db_df.loc[dt_now,'dt_training_start'] = training_start_datetime\n",
    "    predictions_link_db_df.loc[dt_now,'dt_training_end'] = training_end_datetime\n",
    "\n",
    "    # saving the prediction_links database\n",
    "    predictions_link_db_df.to_csv(DATABASE_PATH_ROOT+PREDICTIONS_LINK_DB_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "359e4629-7c89-49f2-8f0a-6a97663d7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_weekly_predictions(cam_ids=cam_ids, \n",
    "#                         training_start_datetime=dt(2022,11,14), \n",
    "#                         training_end_datetime=dt(2022,11,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9fa9d-9296-4d4b-bf55-c9d9556e38b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
