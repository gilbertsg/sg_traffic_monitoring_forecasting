{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63539870-d306-4562-a860-28395d58a827",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c80e29f-e2e1-46de-b18d-9f911932672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "\n",
    "import ast\n",
    "import requests\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# import glob\n",
    "# import shutil\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988624a9-63e5-428a-a57a-78bdd95e931c",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329a4f00-4e2f-4aca-a8f4-49a58123919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTS\n",
    "\n",
    "# database locations\n",
    "DATABASE_PATH_ROOT = '../production/database/'\n",
    "LINKS_DB_FILENAME = 'links_db.csv'\n",
    "IMG_PATH_DB_FILENAME = 'img_path_db.csv'\n",
    "VEHICLE_COUNT_DB_FILENAME = 'vehicle_count_db.csv'\n",
    "\n",
    "# image download variables\n",
    "IMG_LINK_PREFIX ='https://images.data.gov.sg/api/traffic-images/'\n",
    "IMAGES_PATH_ROOT =  '../production/images/'\n",
    "\n",
    "# image processing variables\n",
    "YOLO_DNN_WEIGHTS_PATH = \"../dnn_model/yolov7.weights\"\n",
    "YOLO_DNN_CFG_PATH = \"../dnn_model/yolov7.cfg\"\n",
    "IMAGE_MASK_PATH_ROOT = '../production/image_masks/'\n",
    "OUTPUT_IMAGES_PATH_ROOT =  '../production/processed_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074fdb26-8f1b-4b25-b8dc-ef0deff3c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LIST OF IMPROVEMENTS\n",
    "# - use blaze to load up data faster\n",
    "# - make a bulk download and bulk inference module to catch up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae9ac1-d2fb-4891-8bde-6c7a51b34eec",
   "metadata": {},
   "source": [
    "# Links Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a43bcb9-d52d-4f13-8c0e-d95be48aa6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LINKS DOWNLOADS\n",
    "\n",
    "def call_lta_api(datetime_call):\n",
    "    '''\n",
    "    This function calls the LTA traffic images API based on a certain datetime and returns a datafrane row with the time as index and camera_ids as column\n",
    "    '''\n",
    "\n",
    "    # getting the api call\n",
    "    api = 'https://api.data.gov.sg/v1/transport/traffic-images?date_time='+ \\\n",
    "    datetime_call.strftime(\"%Y-%m-%d\") + \"T\" + datetime_call.strftime(\"%H\") + \"%3A\" + datetime_call.strftime(\"%M\") + \"%3A00\"\n",
    "    \n",
    "    # reading the camera data from data.gov.sg\n",
    "    list_of_camera_info = ast.literal_eval(requests.get(api).content.decode(\"utf-8\"))[\"items\"][0][\"cameras\"]\n",
    "\n",
    "    # instantiating a dataframe to contain the output\n",
    "    output = pd.DataFrame()\n",
    "    \n",
    "    for item in list_of_camera_info: # iterating through each item in the list\n",
    "        item_series = pd.Series(item['image'].replace(IMG_LINK_PREFIX,''), # getting the image names and removing the IMG_LINK_PREFIX to save space\n",
    "                                index=[(pd.to_datetime(item['timestamp']) # setting the index as the timestamp (all series will be concatenated using this index)\n",
    "                                       .replace(tzinfo=None))], # removing the timezone information\n",
    "                                name=item['camera_id']) # setting the name/column_name as the camera ID for storage in database\n",
    "        output = pd.concat([output, item_series],axis=1) # concatenating\n",
    "    \n",
    "    # dropping these cameras as they have been shown to have problems with having different polling time compared to the other cams\n",
    "    output = output.drop(['1001','1002','1003','1004','1005','1006'],axis=1)\n",
    "    \n",
    "    # checking if there are any asynchronous camera links (i.e.: cameras link occur at more than one timestamp, resulting in multiple rows/timestamps for one call)\n",
    "    is_asynchronous = output.isna().sum().sum() > 0\n",
    "    \n",
    "    if is_asynchronous:\n",
    "        output = (output.fillna(method='bfill').fillna(method='ffill'). # fill all rows (timecode) in each column (camera) with the non-null_value in that column\n",
    "                  sort_index(ascending=False).iloc[[0]]) # then condense the whole dataframe to one row by selecting the latest timecode\n",
    "    \n",
    "    # returning the output\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def download_links(datetime_call):\n",
    "    '''\n",
    "    This function takes a datetime object and obtains the links from the LTA API based on the datetime\n",
    "    It will then save the links in the links_db\n",
    "    The function will first check if the called datetime is already available in the links_db, if so, it will skip the download\n",
    "    \n",
    "    \n",
    "    ### NOTES:\n",
    "    This function loads up the entire links_db during its function call, a more efficient system would involve a SQL database, which will be implemented in the future\n",
    "    \n",
    "    Ideally, this function will only be called sequentially (i.e.: only called once every 5 minutes, and no historical calls), this is to make sure that the links_db is always sorted\n",
    "    However, for simplicity purposes, the links_db dataframe will be sorted at the end of the function, this is highly inefficient as links_db gets larger\n",
    "    When deployed using the scheduler, this sorting step will be skipped\n",
    "    '''\n",
    "    \n",
    "    # loads the links database from csv\n",
    "    links_db_df = pd.read_csv(DATABASE_PATH_ROOT+LINKS_DB_FILENAME,index_col=0)\n",
    "    links_db_df.index = pd.to_datetime(links_db_df.index) # converting the index to datetime\n",
    "    \n",
    "    # checking if timestamp is already available in the links_db\n",
    "    df_is_empty = links_db_df.loc[datetime_call-timedelta(minutes=5):datetime_call].empty\n",
    "    \n",
    "    # IF NOT AVAIL\n",
    "    if df_is_empty:\n",
    "\n",
    "        # downloads the list of links from the API and adding it to the end of the dataframe\n",
    "        new_links_df_row = call_lta_api(datetime_call) # downloads links using the function to generate a new row\n",
    "        links_db_df = pd.concat([links_db_df,new_links_df_row],axis=0) # adding the row to the bottom of the links_db dataframe\n",
    "\n",
    "        # sorting the dataframe\n",
    "        ## WILL BE SKIPPED FOR WHEN USING THE SCHEDULER\n",
    "        links_db_df = links_db_df.sort_index()\n",
    "\n",
    "        # saves the dataframe to the links_db.csv\n",
    "        links_db_df.to_csv(DATABASE_PATH_ROOT+LINKS_DB_FILENAME)\n",
    "    \n",
    "    # additionally returns the updated links_db_df (for when this function is called to update the database)\n",
    "    return links_db_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd3fa3-ac8b-4352-ad00-e2fdab079b97",
   "metadata": {},
   "source": [
    "# Images Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d35d31-bb2e-42b9-aae6-e0f675d42478",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMAGES DOWNLOADS\n",
    "\n",
    "def get_image_link(cam_id_call,datetime_call):\n",
    "    '''\n",
    "    This function takes the camera_id and date_time to be called and outputs the download link and download_path for the image file\n",
    "    The download link is obtained from the links_db, if no link is present in the links_db (because it's not been downloaded yet), it will attempt to download the links\n",
    "    \n",
    "    ### NOTES:\n",
    "    This function loads up the entire links_db during its function call, a more efficient system would involve a SQL database, which will be implemented in the future\n",
    "    '''\n",
    "    # LOADING DATABASE\n",
    "    # loads the links database from csv\n",
    "    links_db_df = pd.read_csv(DATABASE_PATH_ROOT+LINKS_DB_FILENAME,index_col=0)\n",
    "    links_db_df.index = pd.to_datetime(links_db_df.index) # converting the index to datetime\n",
    "    \n",
    "    cam_id_call = str(cam_id_call)\n",
    "    \n",
    "    # CHECKING (AND DOWNLOADING) LINKS\n",
    "    # checks the availability of the link\n",
    "    link_is_empty = links_db_df.loc[datetime_call-timedelta(minutes=5):datetime_call,cam_id_call].empty\n",
    "\n",
    "    # downloads the links if the link is empty\n",
    "    if link_is_empty:\n",
    "        links_db_df = download_links(datetime_call=datetime_call)\n",
    "    \n",
    "    # GETTING THE IMAGE LINK\n",
    "    # obtain the image link from the links_db\n",
    "    img_link = links_db_df.loc[datetime_call-timedelta(minutes=5):datetime_call,cam_id_call][0]\n",
    "    \n",
    "    # GETTING THE IMAGE FILENAME AND PATH\n",
    "    # obtain the image timestamp from the links_db\n",
    "    img_timestamp = links_db_df.loc[datetime_call-timedelta(minutes=5):datetime_call,cam_id_call].index[0]\n",
    "    \n",
    "    # decide the name of the image file based on the camera_id and time\n",
    "    img_filename = (\"-\".join([str(cam_id_call), # get the camera_id\n",
    "                              img_timestamp.strftime(\"%Y_%m_%d_%H_%M\"), # get the timestamp\n",
    "                             ]) # combine the cam_id and timestamp with a dash '-'\n",
    "                    + '.jpg') # add .jpg as filetype\n",
    "    \n",
    "    # decide the path of the image file based on the camera_id and time\n",
    "    img_path = (\"/\".join([img_timestamp.strftime(\"%Y_%m_%d\"), # get the date\n",
    "                          str(cam_id_call), # get the camera_id\n",
    "                             ]) # combine the cam_id and timestamp with a slash '/' (indicating folder structure)\n",
    "               +'/') # add / for final folder path\n",
    "    \n",
    "    return img_link, img_filename, img_path\n",
    "\n",
    "\n",
    "\n",
    "def download_image_from_link(img_link, img_filename, img_path):\n",
    "    '''\n",
    "    This function downloads the image from the data.gov api based on its link and puts it in the proper filepath and filename\n",
    "    '''\n",
    "    \n",
    "    # getting full image link\n",
    "    img_link = IMG_LINK_PREFIX+img_link\n",
    "    \n",
    "    # getting full image download path\n",
    "    img_path = IMAGES_PATH_ROOT+img_path\n",
    "    \n",
    "    # getting the file from the url\n",
    "    r = requests.get(img_link, allow_redirects=True)\n",
    "    \n",
    "    # create folder if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(img_path), exist_ok=True)\n",
    "\n",
    "    # combining the path and filename to get the full path\n",
    "    full_path = img_path + '/' + img_filename \n",
    "    \n",
    "    # writing the file to the path\n",
    "    with open(full_path, 'wb') as f: \n",
    "        f.write(r.content)\n",
    "        \n",
    "        \n",
    "def image_downloader(cam_id_call,datetime_call):\n",
    "    '''\n",
    "    This function takes a the cam_id and timestamp and attempts to download the traffic images using links from links_db and save the path to img_path_db\n",
    "    The function will first check if the called datetime and cam_id is already available in the img_path_db, if so, it will skip the download\n",
    "    \n",
    "    \n",
    "    ### NOTES:\n",
    "    This function loads up the entire img_path_db during its function call, a more efficient system would involve a SQL database, which will be implemented in the future\n",
    "    \n",
    "    Ideally, this function will only be called sequentially (i.e.: only called once every 5 minutes, and no historical calls), this is to make sure that the img_path_db is always sorted\n",
    "    However, for simplicity purposes, the img_path_db dataframe will be sorted at the end of the function, this is highly inefficient as links_db gets larger\n",
    "    When deployed using the scheduler, this sorting step will be skipped\n",
    "    '''\n",
    "    # LOADING DATABASE\n",
    "    # loads the img_path database from csv\n",
    "    img_path_db_df = pd.read_csv(DATABASE_PATH_ROOT+IMG_PATH_DB_FILENAME,index_col=0)\n",
    "    img_path_db_df.index = pd.to_datetime(img_path_db_df.index) # converting the index to datetime\n",
    "    \n",
    "    \n",
    "    # CHECKING CAMERA ID\n",
    "    # converts the cam_id_call to a string for indexing\n",
    "    cam_id_call = str(cam_id_call)\n",
    "    \n",
    "    # checks if cam_id_call is part of the available camera\n",
    "    if cam_id_call not in (img_path_db_df.columns):\n",
    "        raise Exception(\"No such camera ID\") # throws error if there is no such camera ID\n",
    "    \n",
    "    \n",
    "    # CHECKING IF IMAGE IS ALREADY PRESENT FROM THE img_path_db\n",
    "    is_img_path_absent = img_path_db_df.loc[datetime_call-timedelta(minutes=5):datetime_call,str(cam_id_call)].dropna().empty\n",
    "    \n",
    "    # skipping out of this function if the img_path is NOT absent (i.e.: if image is already downloaded)\n",
    "    if not is_img_path_absent:\n",
    "        return None\n",
    "    \n",
    "    # GETTING THE IMAGE FROM THE API AND SAVING THE PATH TO img_path_db\n",
    "    # getting the img link, filename, and path from the get_image link function\n",
    "    img_link, img_filename, img_path = get_image_link(cam_id_call=cam_id_call,datetime_call=datetime_call)\n",
    "    \n",
    "    # downloading the image\n",
    "    download_image_from_link(img_link, img_filename, img_path)\n",
    "    \n",
    "    # getting the image timestamp from the filename\n",
    "    yr,mo,dy,hr,mn = img_filename[5:9], img_filename[10:12], img_filename[13:15], img_filename[16:18], img_filename[19:21] # getting the datetime stamp\n",
    "    yr,mo,dy,hr,mn = [int(x) for x in [yr,mo,dy,hr,mn]] # converting the datetime stamp to integers\n",
    "    img_timestamp = dt(yr,mo,dy,hr,mn)\n",
    "    \n",
    "    # getting the image full path\n",
    "    img_full_path = img_path + img_filename\n",
    "    \n",
    "    # adding the full path to the img_path_db\n",
    "    img_path_db_df.loc[img_timestamp,str(cam_id_call)] = img_full_path\n",
    "    \n",
    "    # sorting the dataframe\n",
    "    ## WILL BE SKIPPED FOR WHEN USING THE SCHEDULER\n",
    "    img_path_db_df = img_path_db_df.sort_index()\n",
    "    \n",
    "    # saving the img_path_db\n",
    "    img_path_db_df.to_csv(DATABASE_PATH_ROOT+IMG_PATH_DB_FILENAME)\n",
    "    \n",
    "    # additionally returns the updated img_path_db_df (for when this function is called to update the database)\n",
    "    return img_path_db_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbac8d3c-ecf1-4949-85ed-f0f2fc060d52",
   "metadata": {},
   "source": [
    "# Vehicle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "383a1e3a-4b49-4447-a22d-f8b7bf757a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VEHICLE COUNTER\n",
    "\n",
    "class VehicleDetector:\n",
    "    '''\n",
    "    This class is used to contain the vehicle detector using the pretrained YOLOv7\n",
    "    Using self.class_allowed, the user can filter which types of objects (or vehicles) that is detected\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        # initialize the class by loading the pre-trained model and setting the allowable classes\n",
    "        \n",
    "        # Load DNN from pre-trained model\n",
    "        net = cv2.dnn.readNet(YOLO_DNN_WEIGHTS_PATH, YOLO_DNN_CFG_PATH)\n",
    "        \n",
    "        # setup model and parameters\n",
    "        self.model = cv2.dnn_DetectionModel(net)\n",
    "        self.model.setNmsAcrossClasses(True) # setting so that the NMS applies across different classes (if not will simul. detect car and truck)\n",
    "        self.model.setInputParams(size=(832, 832), scale=1 / 255)\n",
    "\n",
    "        # Allow classes containing Vehicles only\n",
    "        self.classes_allowed = [1, 2, 3, 5, 7] # classes are same as COCO class, but SUBTRACT BY ONE, \n",
    "        # i.e.: {1:'bicycle', 2:'car',3:'motorcycle', 5:'bus', 7:'truck'}\n",
    "\n",
    "    def get_bounding_box(self, img):\n",
    "        '''\n",
    "        This function takes an image and returns the bounding boxes\n",
    "        '''\n",
    "        \n",
    "        # Create a list to contain all detected instance of vehicles\n",
    "        vehicle_boxes = []\n",
    "        \n",
    "        # detect if a none-type image is loaded (could be because of image error) and returns an error, this will be caught later in the main detection function\n",
    "        if img is None:\n",
    "            vehicle_boxes = ['image_error!']\n",
    "            return vehicle_boxes\n",
    "        \n",
    "        # Detect Objects\n",
    "        class_ids, scores, boxes = self.model.detect(img, \n",
    "                                                     nmsThreshold=0.5, # NMS threshold --> higher = more close boxes together\n",
    "                                                     confThreshold=0.15)\n",
    "        \n",
    "        # looping through each object detected\n",
    "        for class_id, score, box in zip(class_ids, scores, boxes):\n",
    "            # if the object is within the allowed class, then add the item in the vehicle_boxes list\n",
    "            if class_id in self.classes_allowed:\n",
    "                vehicle_boxes.append({'class_id':class_id+1,\n",
    "                                      'score':score,\n",
    "                                      'box':box})\n",
    "                \n",
    "        return vehicle_boxes\n",
    "    \n",
    "    \n",
    "    def preprocess(self, img, mask_path=None): \n",
    "        '''\n",
    "        This is a helper function to preprocess the image given a mask\n",
    "        In this particular instance, no further preprocessing was implemented,\n",
    "        but in theory, sharpening or contrast correction could be added here to help the image detection algorithm\n",
    "        '''\n",
    "        # load mask from directory\n",
    "        if mask_path==None: # if no maks is specified, then generate a white mask (i.e.: everything will pass)\n",
    "            mask = np.zeros((1080,1920),dtype=np.uint8)\n",
    "            mask[:] = 255\n",
    "\n",
    "        else: # if a mask is specified, then use the pre-defined mask\n",
    "            mask = cv2.imread(mask_path)\n",
    "            mask = cv2.cvtColor(mask,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # masking image using the pre-defined mask\n",
    "        img = cv2.bitwise_or(img,img,mask=mask)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def process_image(self, img, mask_path=None):\n",
    "        '''\n",
    "        This function returns the processed image and total vehicle count given an image and a mask_path (used for masking the camera to only the ROI)\n",
    "        There are various error catching function here which will raise a warning if the function is unable to conduct the preprocessing or detection\n",
    "        '''\n",
    "        # INITIALIZATION\n",
    "        # define vehicle dictionary\n",
    "        object_dictionary = {2:'bicycle',3:'car',4:'motorcycle',6:'bus',8:'truck'}\n",
    "\n",
    "        # print error if image failed to load\n",
    "        if img is None:\n",
    "            print(f'error in loading image {img_filename}')\n",
    "\n",
    "        # create a clean copy (without masking or preprocessing) to be outputed later with the bounding boxes\n",
    "        output_img = img.copy() \n",
    "\n",
    "        # PREPROCESSING\n",
    "        # attempt to preprocess and mask the image\n",
    "        try:\n",
    "            img = self.preprocess(img=img,\n",
    "                                  mask_path=mask_path)\n",
    "        # if masking fails (due to absence of mask or other things) use the original image\n",
    "        except:\n",
    "            img = output_img\n",
    "            warnings.warn(\"Warning: Image Preprocessing Error\")\n",
    "            \n",
    "        # DETECTING VEHICLES\n",
    "        # use the get_bounding_box function to return the vehicle boxes\n",
    "        vehicle_boxes = self.get_bounding_box(img)\n",
    "\n",
    "        # error catching for detection error\n",
    "        if vehicle_boxes == ['image_error!']:\n",
    "            warnings.warn(\"Warning: Image Detection Error\")\n",
    "\n",
    "        # counting number of vehicles\n",
    "        vehicle_count = len(vehicle_boxes)\n",
    "\n",
    "        # DRAWING BOUNDING BOXES\n",
    "        for vehicle_box in vehicle_boxes:\n",
    "            x, y, w, h = vehicle_box['box']\n",
    "\n",
    "            cv2.rectangle(output_img, (x, y), (x + w, y + h), (25, 0, 180), 3)\n",
    "            cv2.putText(output_img, f\"{object_dictionary[vehicle_box['class_id']]} | {vehicle_box['score']:.2f}\", (x, y + h), 0, 1, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.putText(output_img, \"Vehicle count: \" + str(vehicle_count), (20, 50), 0, 2, (100, 200, 0), 3)\n",
    "\n",
    "        return output_img, vehicle_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1db6a0-64bb-40e4-a373-ca4c42d8c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vehicle_count(cam_id_call, datetime_call):\n",
    "    '''\n",
    "    This function takes in the camera_id and datetime and runs a vehicle detection on the corresponding image\n",
    "    If the image is not yet downloaded, the function will attempt to download the image\n",
    "    The function will also return\n",
    "    '''\n",
    "    # LOADING DATABASE\n",
    "    # loads the img_path database from csv\n",
    "    img_path_db_df = pd.read_csv(DATABASE_PATH_ROOT+IMG_PATH_DB_FILENAME,index_col=0)\n",
    "    img_path_db_df.index = pd.to_datetime(img_path_db_df.index) # converting the index to datetime\n",
    "    \n",
    "    # loads the img_path database from csv\n",
    "    vehicle_count_db_df = pd.read_csv(DATABASE_PATH_ROOT+VEHICLE_COUNT_DB_FILENAME,index_col=0)\n",
    "    vehicle_count_db_df.index = pd.to_datetime(vehicle_count_db_df.index) # converting the index to datetime\n",
    "    \n",
    "    \n",
    "    # CHECKING CAMERA ID\n",
    "    # converts the cam_id_call to a string for indexing\n",
    "    cam_id_call = str(cam_id_call)\n",
    "    \n",
    "    # checks if cam_id_call is part of the available camera\n",
    "    if cam_id_call not in (img_path_db_df.columns):\n",
    "        raise Exception(\"No such camera ID\") # throws error if there is no such camera ID\n",
    "    \n",
    "    \n",
    "    # CHECKING IF IMAGE HAS BEEN DOWNLOADED FROM THE img_path_db\n",
    "    is_img_path_absent = img_path_db_df.loc[datetime_call-timedelta(minutes=5):datetime_call,str(cam_id_call)].dropna().empty\n",
    "    \n",
    "    # downloads the image if the image is absent\n",
    "    if is_img_path_absent: \n",
    "        img_path_db_df = image_downloader(cam_id_call=cam_id_call, datetime_call=datetime_call)\n",
    "        \n",
    "        \n",
    "    # CHECKING IF IMAGE HAS BEEN PROCESSED FROM THE vehicle_count_db\n",
    "    is_vehicle_count_absent = vehicle_count_db_df.loc[datetime_call-timedelta(minutes=5):datetime_call,str(cam_id_call)].dropna().empty\n",
    "    \n",
    "    # skips the vehicle count if image has already been processed (i.e.: NOT absent)\n",
    "    if not is_vehicle_count_absent: \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    # GETTING THE IMAGE PATH FROM img_path_db\n",
    "    img_path = img_path_db_df.loc[datetime_call-timedelta(minutes=5):datetime_call,str(cam_id_call)][0]\n",
    "    \n",
    "    # getting the image timestamp from the filename\n",
    "    img_filename = os.path.basename(img_path)\n",
    "    yr,mo,dy,hr,mn = img_filename[5:9], img_filename[10:12], img_filename[13:15], img_filename[16:18], img_filename[19:21] # getting the datetime stamp\n",
    "    yr,mo,dy,hr,mn = [int(x) for x in [yr,mo,dy,hr,mn]] # converting the datetime stamp to integers\n",
    "    img_timestamp = dt(yr,mo,dy,hr,mn)\n",
    "    \n",
    "    # VEHICLE DETECTION\n",
    "    # Load Veichle Detector class\n",
    "    vd = VehicleDetector()\n",
    "\n",
    "    # read the image from path\n",
    "    img = cv2.imread(IMAGES_PATH_ROOT+img_path)\n",
    "    \n",
    "    # obtain mask_path from cam_id\n",
    "    mask_path = IMAGE_MASK_PATH_ROOT+str(cam_id_call)+'.jpg'\n",
    "    \n",
    "    # getting the processed image and vehicle count from the process_image function\n",
    "    output_img, vehicle_count = vd.process_image(img=img,mask_path=mask_path)\n",
    "    \n",
    "    # saving processed image\n",
    "    img_path_out = OUTPUT_IMAGES_PATH_ROOT + img_path # getting the output image path\n",
    "    os.makedirs(os.path.dirname(img_path_out), exist_ok=True) # create folder if doesn't exist\n",
    "    cv2.imwrite(img_path_out, output_img) # writing the image to the output folder\n",
    "    \n",
    "    # SAVING VEHICLE_COUNT TO DATABASE\n",
    "    # adding the vehicle count to the img_path_db\n",
    "    vehicle_count_db_df.loc[img_timestamp,str(cam_id_call)] = int(vehicle_count)\n",
    "    \n",
    "    # sorting the dataframe\n",
    "    ## WILL BE SKIPPED FOR WHEN USING THE SCHEDULER\n",
    "    vehicle_count_db_df = vehicle_count_db_df.sort_index()\n",
    "    \n",
    "    # saving the img_path_db\n",
    "    vehicle_count_db_df.to_csv(DATABASE_PATH_ROOT+VEHICLE_COUNT_DB_FILENAME)\n",
    "    \n",
    "    \n",
    "    # # displaying the image (only for debugging)\n",
    "    # plt.figure(figsize=(20,20))\n",
    "    # plt.imshow(cv2.cvtColor(output_img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b9798-f7a2-4c83-98b8-9d5abaa5f0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ee8e5-ef47-4444-a631-2953535406c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3bd26f0-6872-41b6-bd83-fcacb65fb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle_count(cam_id_call=1702, datetime_call=dt(2022,11,12,18,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf5a1f6-9672-46bd-a301-ba4ed2317fd2",
   "metadata": {},
   "source": [
    "# Catch Up Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47522d7a-1d55-43c0-830e-59cac2ee1eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f88f5c515d745dcadbc1a534b0712ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in processing 6708 at 2022-11-27 10-40\n",
      "error in processing 6708 at 2022-11-27 01-10\n",
      "error in processing 6708 at 2022-11-26 14-30\n",
      "error in processing 6708 at 2022-11-26 08-30\n",
      "error in processing 6708 at 2022-11-26 01-10\n",
      "error in processing 6708 at 2022-11-25 01-10\n",
      "error in processing 6708 at 2022-11-24 06-10\n",
      "error in processing 6708 at 2022-11-24 01-10\n",
      "error in processing 6708 at 2022-11-23 18-40\n",
      "error in processing 6708 at 2022-11-23 01-10\n",
      "error in processing 6708 at 2022-11-22 01-10\n",
      "error in processing 6708 at 2022-11-21 18-50\n",
      "error in processing 6708 at 2022-11-21 11-20\n",
      "error in processing 6708 at 2022-11-21 01-10\n",
      "error in processing 2706 at 2022-11-27 10-40\n",
      "error in processing 2706 at 2022-11-27 01-10\n",
      "error in processing 2706 at 2022-11-26 08-30\n",
      "error in processing 2706 at 2022-11-26 01-10\n"
     ]
    }
   ],
   "source": [
    "### CATCH UP SPECIFIC TIME\n",
    "### SPECIFIC CAMERA\n",
    "\n",
    "# cam_ids = [1702,2705,2706,3702,3793,3797,4702,4706,4708,4799,5795,6704,6708,6710,6715,7793,7794,7797,8701,8704,9706]\n",
    "cam_ids = [6708,2706,6710,4702,1702,3793] # selected cameras\n",
    "cam_id_list = cam_ids\n",
    "\n",
    "\n",
    "dt_start = dt(2022,11,21,0,0)\n",
    "dt_end = dt(2022,11,28,0,0)\n",
    "# dt_end = dt.now()\n",
    "dt_resolution_mins = 10\n",
    "num_of_observations = round((dt_end-dt_start)/timedelta(minutes=dt_resolution_mins))\n",
    "dt_list = [dt_end - timedelta(minutes=x*dt_resolution_mins) for x in range(num_of_observations)]\n",
    "\n",
    "combo_list = list(itertools.product(cam_id_list,dt_list))\n",
    "combo_list_pbar = tqdm(combo_list)\n",
    "\n",
    "for cam_id, dt_call in combo_list_pbar:\n",
    "    try: vehicle_count(cam_id_call=cam_id, datetime_call=dt_call)\n",
    "    except: print(f'error in processing {cam_id} at {dt_call.strftime(\"%Y-%m-%d %H-%M\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c72bd5bb-bd93-4bb5-a931-f82e8c96c6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d9a35db7264e8c85d4d031304ccee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in processing 6708 at 2022-12-01 17-37\n",
      "error in processing 6708 at 2022-12-01 17-07\n",
      "error in processing 2706 at 2022-12-01 17-37\n",
      "error in processing 2706 at 2022-12-01 17-07\n",
      "error in processing 6710 at 2022-12-01 17-37\n",
      "error in processing 6710 at 2022-12-01 17-07\n",
      "error in processing 4702 at 2022-12-01 17-37\n",
      "error in processing 4702 at 2022-12-01 17-07\n",
      "error in processing 1702 at 2022-12-01 17-37\n",
      "error in processing 1702 at 2022-12-01 17-07\n",
      "error in processing 3793 at 2022-12-01 17-37\n",
      "error in processing 3793 at 2022-12-01 17-07\n"
     ]
    }
   ],
   "source": [
    "# ### CATCH UP TODAY\n",
    "# ### ALL CAMERAS\n",
    "\n",
    "\n",
    "# # cam_ids = [1702,2705,2706,3702,3793,3797,4702,4706,4708,4799,5795,6704,6708,6710,6715,7793,7794,7797,8701,8704,9706]\n",
    "# cam_ids = [6708,2706,6710,4702,1702,3793] # selected cameras\n",
    "# cam_id_list = cam_ids\n",
    "\n",
    "\n",
    "# dt_start = dt.now().replace(hour=17, minute=0,second=0)\n",
    "# dt_end = dt.now()\n",
    "# # dt_end = dt.now()\n",
    "# dt_resolution_mins = 10\n",
    "# num_of_observations = round((dt_end-dt_start)/timedelta(minutes=dt_resolution_mins))\n",
    "# dt_list = [dt_end - timedelta(minutes=x*dt_resolution_mins) for x in range(num_of_observations)]\n",
    "\n",
    "# combo_list = list(itertools.product(cam_id_list,dt_list))\n",
    "# combo_list_pbar = tqdm(combo_list)\n",
    "\n",
    "# for cam_id, dt_call in combo_list_pbar:\n",
    "#     try: vehicle_count(cam_id_call=cam_id, datetime_call=dt_call)\n",
    "#     except: print(f'error in processing {cam_id} at {dt_call.strftime(\"%Y-%m-%d %H-%M\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60bed303-cf03-4c28-86d1-7fdcd0ea46b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approx 4 hours of active time per day in amazon sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b0284-3caa-4e64-8d9c-1e80f6d45ea1",
   "metadata": {},
   "source": [
    "# Constant Update Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1228f195-51d0-4310-b4be-2f8a692d7eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b541c2a4d54320b7d52355e106757f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cam_id_list = [6708,2706,6710,4702,1702,3793]\n",
    "# dt_list = [dt.now()]\n",
    "\n",
    "# combo_list = list(itertools.product(cam_id_list,dt_list))\n",
    "# combo_list_pbar = tqdm(combo_list)\n",
    "\n",
    "# for cam_id, dt_call in combo_list_pbar:\n",
    "#     try: vehicle_count(cam_id_call=cam_id, datetime_call=dt_call)\n",
    "#     except: print(f'error in processing {cam_id} at {dt_call.strftime(\"%Y-%m-%d %H-%M\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f38868-0932-4e5c-8b82-e77b802115db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e69c6c6-b969-479c-b9a4-c96506197d9c",
   "metadata": {},
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ccde0-554b-4e2b-ba0d-a1b9e792d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(cam_id, starting_datetime_for_training_week):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9b040-c005-40e5-99ef-d498662aa602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492e038-c1cc-4648-9750-eb3bce75c8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674c109-86ce-4f9a-a172-fcae6dbb905b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5befd25-7ff4-426e-b5d2-4f84da9ba7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_predictions(cam_id, week):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9914e2f-71ae-4e6b-aaaa-a66356550386",
   "metadata": {},
   "source": [
    "# Generate Traffic Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa3c60-a631-42ea-bfb2-d93bee448210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74796dbd-de0e-473d-ba0b-934d523eb488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35323b52-9ebd-4dd1-8456-298ed49cd967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff0e8e-d327-4a51-8a66-d419de045a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8c21d0-c261-448a-b9fb-0ff663ff7b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
