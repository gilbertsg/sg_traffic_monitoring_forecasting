{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "667f36ba-a8a0-4651-a13a-13a2d9402eae",
   "metadata": {},
   "source": [
    "# Process Overview for Downloading Traffic Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b7d660-2468-4faf-a45a-52c3e72ee8fb",
   "metadata": {},
   "source": [
    "As previously mentioned, the data.gov.sg API only returns the link to the traffic images (which is stored in a static server). Therefore, the next process would be to use the previously scraped images link and download the traffic images.\n",
    "\n",
    "The following are several example of the traffic images:\n",
    "![image](../images/notebook_images/traffic_images_samples.jpg)\n",
    "\n",
    "In this notebook, we will be downloading the traffic images from selected cameras (22) for the entire month of October, as well as the first two weeks of November. The cameras are selected based on varying locations, spanning all across Singapore.\n",
    "\n",
    "The total number of images downloaded for this study is 195,093 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408ce07f-f05e-4805-b485-bb2f080992fa",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a023cc8-b994-4681-a665-afa78e216c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "import requests\n",
    "import ast\n",
    "import numpy as np\n",
    "import urllib \n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37118335-5944-49b3-b9b8-4e8c97c4121b",
   "metadata": {},
   "source": [
    "# Reading links dataframe from storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a7cb9a-3295-483f-a922-5851557ea795",
   "metadata": {},
   "source": [
    "We will first load the image links from the .csv file obtained in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720f5873-ce17-4570-9159-bc4aeeded9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>image</th>\n",
       "      <th>camera_id</th>\n",
       "      <th>md5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-30 23:57:15</td>\n",
       "      <td>2022/09/ccfae87c-d330-4ccd-a1e7-a0c94062f94b.jpg</td>\n",
       "      <td>1001</td>\n",
       "      <td>6b7cf877b837a2c584d69cc989e2791c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-30 23:57:15</td>\n",
       "      <td>2022/09/b95185f7-69a8-4fbf-9ed9-69838b4eb101.jpg</td>\n",
       "      <td>1002</td>\n",
       "      <td>fce5e26fa7899b7ecb7757b2998baaae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-30 23:57:15</td>\n",
       "      <td>2022/09/22786a35-99ed-468a-9562-968cb64aecd0.jpg</td>\n",
       "      <td>1003</td>\n",
       "      <td>0e4cca557d25c51459d866ce51f958bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-30 23:57:15</td>\n",
       "      <td>2022/09/c084a08b-c7c8-4eed-8adb-e982792cfdbe.jpg</td>\n",
       "      <td>1004</td>\n",
       "      <td>d4e4ea3ca7060440d154f75b33c74b6c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-30 23:57:15</td>\n",
       "      <td>2022/09/86850290-63ec-4b24-819a-5c8cd57497d7.jpg</td>\n",
       "      <td>1005</td>\n",
       "      <td>8e381cc6bb4eb77d7c2028796ff5efbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771910</th>\n",
       "      <td>2022-10-31 23:52:25</td>\n",
       "      <td>2022/10/72b7c3a8-57d2-4895-83f6-da4bb3a16ff4.jpg</td>\n",
       "      <td>9702</td>\n",
       "      <td>eacdf5702f2e4d7ee1ef682d40a0bd92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771911</th>\n",
       "      <td>2022-10-31 23:52:25</td>\n",
       "      <td>2022/10/7017e4ee-4373-48e5-b6e5-5c470342b5a8.jpg</td>\n",
       "      <td>9703</td>\n",
       "      <td>ba47194f20c29edfe5d3fdde711710b7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771912</th>\n",
       "      <td>2022-10-31 23:52:25</td>\n",
       "      <td>2022/10/688edd73-682f-47e1-b868-17cf21e78a4b.jpg</td>\n",
       "      <td>9704</td>\n",
       "      <td>0c151fbd8dd501e408de598df9f3ec85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771913</th>\n",
       "      <td>2022-10-31 23:52:25</td>\n",
       "      <td>2022/10/563bf0b5-431d-4274-a6ab-61c4ad7fdb61.jpg</td>\n",
       "      <td>9705</td>\n",
       "      <td>2bd974a5cacbe0bdb12182362faeb5eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771914</th>\n",
       "      <td>2022-10-31 23:52:25</td>\n",
       "      <td>2022/10/9deb74c5-cf1f-49a9-90b5-db03f0178e22.jpg</td>\n",
       "      <td>9706</td>\n",
       "      <td>eb37a1ba16d8bbbca54e3e417fa4e9a8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>771915 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp                                             image  \\\n",
       "0      2022-09-30 23:57:15  2022/09/ccfae87c-d330-4ccd-a1e7-a0c94062f94b.jpg   \n",
       "1      2022-09-30 23:57:15  2022/09/b95185f7-69a8-4fbf-9ed9-69838b4eb101.jpg   \n",
       "2      2022-09-30 23:57:15  2022/09/22786a35-99ed-468a-9562-968cb64aecd0.jpg   \n",
       "3      2022-09-30 23:57:15  2022/09/c084a08b-c7c8-4eed-8adb-e982792cfdbe.jpg   \n",
       "4      2022-09-30 23:57:15  2022/09/86850290-63ec-4b24-819a-5c8cd57497d7.jpg   \n",
       "...                    ...                                               ...   \n",
       "771910 2022-10-31 23:52:25  2022/10/72b7c3a8-57d2-4895-83f6-da4bb3a16ff4.jpg   \n",
       "771911 2022-10-31 23:52:25  2022/10/7017e4ee-4373-48e5-b6e5-5c470342b5a8.jpg   \n",
       "771912 2022-10-31 23:52:25  2022/10/688edd73-682f-47e1-b868-17cf21e78a4b.jpg   \n",
       "771913 2022-10-31 23:52:25  2022/10/563bf0b5-431d-4274-a6ab-61c4ad7fdb61.jpg   \n",
       "771914 2022-10-31 23:52:25  2022/10/9deb74c5-cf1f-49a9-90b5-db03f0178e22.jpg   \n",
       "\n",
       "        camera_id                               md5  \n",
       "0            1001  6b7cf877b837a2c584d69cc989e2791c  \n",
       "1            1002  fce5e26fa7899b7ecb7757b2998baaae  \n",
       "2            1003  0e4cca557d25c51459d866ce51f958bb  \n",
       "3            1004  d4e4ea3ca7060440d154f75b33c74b6c  \n",
       "4            1005  8e381cc6bb4eb77d7c2028796ff5efbf  \n",
       "...           ...                               ...  \n",
       "771910       9702  eacdf5702f2e4d7ee1ef682d40a0bd92  \n",
       "771911       9703  ba47194f20c29edfe5d3fdde711710b7  \n",
       "771912       9704  0c151fbd8dd501e408de598df9f3ec85  \n",
       "771913       9705  2bd974a5cacbe0bdb12182362faeb5eb  \n",
       "771914       9706  eb37a1ba16d8bbbca54e3e417fa4e9a8  \n",
       "\n",
       "[771915 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/LTA_traffic_cam_20221001-20221031.csv', parse_dates=['timestamp'])\n",
    "df['timestamp'] = df['timestamp'].dt.tz_localize(None) # remove timezone info\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbeaf64-042a-46c9-b9bb-ed58cffb490d",
   "metadata": {},
   "source": [
    "# Defining Function to Download Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636803a9-c8ec-4c75-abf3-b50f302922ba",
   "metadata": {},
   "source": [
    "First, we will need to define a couple of functions to download the images from the images.data.gov.sg static server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa4e2055-c69c-405b-b51b-2df89b912da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_item(url, filename, path):\n",
    "    '''\n",
    "    This function takes in the URL to download the traffic images from, as well as the file name and path for the images to be saved into\n",
    "    The function will then download the image based on the URL and save it with the filename into the defined path \n",
    "    '''  \n",
    "    # getting the file from the url\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    \n",
    "    # create the folder path if it doesn't exist yet\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    # combining the path and filename to get the full path\n",
    "    full_path = path + '\\\\' + filename \n",
    "    \n",
    "    # writing the file to the path\n",
    "    with open(full_path, 'wb') as f: \n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13650385-313c-4fbf-aadb-71daaf05faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_dataframe(df,download_path,failed_download_list=None):\n",
    "    '''\n",
    "    This function takes in a dataframe containing the links and metadata of the traffic images and then attempts to download all the images whose link is in that dataframe\n",
    "    You will also need to specify the path for the images to be downloaded to\n",
    "    This function will also generate the filename for the images based on the image metadata from the dataframe\n",
    "    If any of the download fails (usually due to timeout from the download server), you can specify a failed download list which you can use to retry the downloads at a later time\n",
    "    '''\n",
    "    \n",
    "    # converting the df into list of dictionaries\n",
    "    df_rows_as_dict = df.to_dict(orient=\"records\")\n",
    "    \n",
    "    # convert the list of df_rows into a tqdm for displaying progress bar\n",
    "    df_rows_as_dict_pbar = tqdm(df_rows_as_dict)\n",
    "    \n",
    "    # create download folder if doesn't exist yet\n",
    "    if not os.path.exists(download_path):\n",
    "        os.makedirs(download_path)\n",
    "    \n",
    "    # iterating to each row in the dataframe\n",
    "    for df_row in df_rows_as_dict_pbar:\n",
    "        \n",
    "        # get the image filename (for saving the image) from row info and join together into a string\n",
    "        filename_from_row = (\"-\".join([str(df_row['camera_id']), # get the camera_id\n",
    "                                      pd.to_datetime(df_row['timestamp']).strftime(\"%Y_%m_%d_%H_%M\"), # get the timestamp\n",
    "                                      df_row['md5']]) #include the md5 hash\n",
    "                            + '.jpg') # add .jpg as filename\n",
    "            \n",
    "        # get the full download url from row info\n",
    "        image_link_prefix='https://images.data.gov.sg/api/traffic-images/'\n",
    "        url_from_row = image_link_prefix + df_row['image']\n",
    "        \n",
    "        # printing out current datetime_call in the tqdm\n",
    "        df_rows_as_dict_pbar.set_description(f'Downloading {df_row[\"image\"]}')\n",
    "\n",
    "        # attempting to download the image\n",
    "        try:\n",
    "            download_item(url = url_from_row,\n",
    "                          filename = filename_from_row,\n",
    "                          path = download_path)\n",
    "        \n",
    "        # error catching if download fails\n",
    "        except:\n",
    "            # notify the user about failed download\n",
    "            print(f'failed to download {url_from_row}')\n",
    "            \n",
    "            # if a failed_download_list has been specified by the user, append the failed download info the the list\n",
    "            if failed_download_list!=None:\n",
    "                \n",
    "                # creating a dictionary of the failed item download\n",
    "                failed_download_dict = {'url':url_from_row,\n",
    "                                        'filename':filename_from_row,\n",
    "                                        'path':download_path}\n",
    "                # appending the dictionary to the list\n",
    "                failed_download_list.append(failed_download_dict)\n",
    "                \n",
    "                \n",
    "                \n",
    "def download_from_failed_download_list(download_list):\n",
    "    '''\n",
    "    This function will download the items from the failed_download_list\n",
    "    '''\n",
    "    # convert the list of df_rows into a tqdm for displaying progress bar\n",
    "    download_list_pbar = tqdm(download_list)\n",
    "    \n",
    "    # iterating through each item in the downloads_list\n",
    "    for dictionary in download_list_pbar:\n",
    "        # downloading the items\n",
    "        download_item(url = dictionary['url'],\n",
    "                      filename = dictionary['filename'],\n",
    "                      path = dictionary['path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd78ef-7a5d-4de0-82a9-ecbe1390653a",
   "metadata": {},
   "source": [
    "# Filtering df to be downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb10a402-c388-495e-b781-87744906213b",
   "metadata": {},
   "source": [
    "We then need to filter the dataframe of links to be downloaded, filtering them by the camera ID as well as the start and ending datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207cd1cd-2dd8-45a7-b429-0c61b4ecaa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df_to_download(df, camera_id_list, start_datetime, end_datetime):\n",
    "    '''\n",
    "    This function is used to filter the pandas dataframe based on the camera ID list and the start and end date time\n",
    "    '''\n",
    "    # masking based on camera_id\n",
    "    camera_mask = df['camera_id'].isin(camera_id_list) # only select camera_id that's in the cam_id_list\n",
    "    df = df[camera_mask]\n",
    "    \n",
    "    # masking based on timestamp\n",
    "    date_mask = (df['timestamp'] >= start_datetime) & (df['timestamp'] <= end_datetime) # only select records that's between the start and end datetime_call\n",
    "    df = df[date_mask]\n",
    "    \n",
    "    df = df.sort_values(['camera_id','timestamp'])\n",
    "    \n",
    "    print(f'No of images to be downloaded: {df.shape[0]}')\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faa06e06-0c74-43a0-8445-029d3c0c8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of camera_ids to download\n",
    "camera_id_list = [1702,2705,2706,3702,3793,3797,4702,4706,4708,4799,5795,6704,6708,6710,6714,6715,7793,7794,7797,8701,8704,9706]\n",
    "\n",
    "# defining start and end datetime\n",
    "start_datetime=datetime.datetime(2022,10,1,0,0,0)\n",
    "end_datetime=datetime.datetime(2022,11,15,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5fccb3a-e883-46fb-b796-8c44126810e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of images to be downloaded: 195093\n"
     ]
    }
   ],
   "source": [
    "df_download = filter_df_to_download(df=df,\n",
    "                                    camera_id_list=camera_id_list, \n",
    "                                    start_datetime=start_datetime, \n",
    "                                    end_datetime=end_datetime,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9580323-cb4f-463e-a9d3-6b91ea340388",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Downloading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a39550f-cf0b-4645-9c6f-39051525b328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2022/09/f36de43b-ba76-4c37-a9fb-c322c0431b1d.jpg: 100%|████████████████████| 44/44 [00:08<00:00,  5.26it/s]\n"
     ]
    }
   ],
   "source": [
    "failed_download_list = []\n",
    "download_path = 'C:/image_downloads_test/'\n",
    "\n",
    "download_from_dataframe(df=df_download,\n",
    "                        download_path=download_path,\n",
    "                        failed_download_list=failed_download_list,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352c6cb8-0801-4c9c-89e9-e70462f6b9b1",
   "metadata": {},
   "source": [
    "## Checking for Failed Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45bd0799-3e16-4362-8f14-b3f591e39453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of failed downloads: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# checking the number of failed downloads\n",
    "print(f'Number of failed downloads: {len(failed_download_list)}')\n",
    "\n",
    "# re-attempting the download of the failed downloads items\n",
    "download_from_failed_download_list(download_list=failed_download_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd5b0e1-9b10-44fb-bc61-d8645979acae",
   "metadata": {},
   "source": [
    "# Arranging Downloaded Images Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ea408-54bc-438f-86fd-928242233e6b",
   "metadata": {},
   "source": [
    "Finally we will arrange the images in the folder according to the camera_id and image capture time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "880a2678-81a9-485a-9c8e-a3a9f8e8bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_arranger(folder_path):\n",
    "    '''\n",
    "    This function takes in a folder path and will arrange the traffic images in that folder according to the camera_id and image capture time\n",
    "    The info regarding the camera_id and image capture time is extracted from the filename of the image\n",
    "    '''\n",
    "    \n",
    "    # getting a list of all the .jpg images in the folder_path\n",
    "    image_paths = glob.glob(pathname=folder_path+\"/**/*.jpg\",\n",
    "                            recursive=True)\n",
    "\n",
    "    # convert the image_paths list into a tqdm for displaying progress bar\n",
    "    image_paths_pbar = tqdm(image_paths)\n",
    "\n",
    "    # iterating through each image in the image_paths list\n",
    "    for image_path in image_paths_pbar:\n",
    "\n",
    "        # get filename\n",
    "        image_filename = os.path.basename(image_path)\n",
    "\n",
    "        # adding description\n",
    "        image_paths_pbar.set_description(f'Arranging folder')\n",
    "        \n",
    "        # get camera_id and date from filename\n",
    "        camera_id = image_filename[0:4]\n",
    "        date = image_filename[5:15]\n",
    "\n",
    "        # assigngs the folder name based onthe camera_id and date\n",
    "        folder_path_to_put_into = folder_path + camera_id + '/' + date + '/'\n",
    "\n",
    "        # create folder if doesn't exist yet\n",
    "        if not os.path.exists(folder_path_to_put_into):\n",
    "            os.makedirs(folder_path_to_put_into)\n",
    "            \n",
    "        # moves the image from image_path to the new folder\n",
    "        shutil.move(src=image_path,\n",
    "                    dst=folder_path_to_put_into+image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbd77694-9eef-4d36-8492-f536c2559a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arranging folder: 100%|███████████████████████████████████████████████████████████████| 44/44 [00:00<00:00, 365.91it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_arranger(folder_path=download_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
