{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cfcd7d5-9e40-4127-a6e2-b465514b8bf8",
   "metadata": {},
   "source": [
    "# Process Overview for Scraping Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa859b-6d1b-430f-9455-0424c1ce4e23",
   "metadata": {},
   "source": [
    "The first step for in this traffic analysis project is to scrape the traffic images from LTA. The traffic images are provided by LTA through the [Datamall API](https://datamall.lta.gov.sg/content/datamall/en/dynamic-data.html):\n",
    "- The API returns traffic images from 87 different locations in Singapore's expressways\n",
    "- The images are updated every 1 to 5 minutes\n",
    "- These images are retraived by data.gov.sg, and wrapped in another API\n",
    "- We will be using the data.gov.sg API for the purposes of this project\n",
    "\n",
    "The process for interacting with the data.gov.sg [Traffic Images API](https://data.gov.sg/dataset/traffic-images) is as follows:\n",
    "- Provide a datetime call to the API\n",
    "- The API will retrieve the latest available data at that moment in time, which will contain the following:\n",
    "    - image metadata (image dimensions, camera longitude & latitude)\n",
    "    - datetime of acquisition\n",
    "    - a static link to the traffic image\n",
    "    - an MD5 hash\n",
    "    \n",
    "Therefore, to obtain the traffic images, we would first need to use the data.gov.sg traffic images API to obtain the links to the images.\n",
    "\n",
    "For the purposes of this study, we will be scraping traffic images from selected cameras for the entire month of October."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408ce07f-f05e-4805-b485-bb2f080992fa",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f3af43-d248-4803-a79d-3b0bab8bbbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "import requests\n",
    "import ast\n",
    "import numpy as np\n",
    "import urllib \n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988cb10a-8a98-40b0-9d8f-54cdeaab0734",
   "metadata": {},
   "source": [
    "# Function Definition for Image Link Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f5996-5938-46a5-ad67-ad9831a8086f",
   "metadata": {},
   "source": [
    "First, we will need to define a couple of functions to interact with the data.gov traffic images API, and then transform the information returned to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8027ac65-e655-4691-9b74-ed5d51a93986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataframe(input_list):\n",
    "    '''\n",
    "    This function converts the output from the API (a list of dictionaries) into a pandas dataframe\n",
    "    '''\n",
    "    \n",
    "    # casting the input list as a dataframe\n",
    "    output = pd.DataFrame(input_list)\n",
    "\n",
    "    # convert location columns from dictionary to columns\n",
    "    output = (pd.concat([output, # concatenating the original output column\n",
    "                         output['location'].apply(pd.Series)], # with the dictionary of data from the location column\n",
    "                        axis=1). # concatenating on columns\n",
    "              drop('location',axis = 1)) # dropping the original location column\n",
    "\n",
    "    # convert image_metadata columns from dictionary to columns\n",
    "    output = (pd.concat([output, # concatenating the original output column\n",
    "                         output['image_metadata'].apply(pd.Series)], # with the dictionary of data from the image_metadata column\n",
    "                        axis=1). # concatenating on columns\n",
    "              drop('image_metadata',axis = 1)) # dropping the original image_metadata column\n",
    "    \n",
    "    # returning the output dataframe\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_lta_traffic_camera_data(datetime_call):\n",
    "    '''\n",
    "    This function converts the datetime_call (in the form of a datetime object) to the required format, and then calls the traffic images API\n",
    "    '''\n",
    "    \n",
    "    # formats the datetime_call\n",
    "    datetime_call_formatted = datetime_call.strftime(\"%Y-%m-%d\") + \"T\" + datetime_call.strftime(\"%H\") + \"%3A\" + datetime_call.strftime(\"%M\") + \"%3A00\" \n",
    "    \n",
    "    # getting the api call\n",
    "    api = 'https://api.data.gov.sg/v1/transport/traffic-images?date_time='+ datetime_call_formatted\n",
    "    \n",
    "\n",
    "    # reading the camera data from data.gov.sg\n",
    "    camera_data = ast.literal_eval(requests.get(api).content.decode(\"utf-8\"))[\"items\"][0][\"cameras\"]\n",
    "\n",
    "    # returning the output, converted as a dataframe\n",
    "    return convert_to_dataframe(camera_data)\n",
    "\n",
    "\n",
    "def lta_traffic_camera_scraping(start_datetime, end_datetime, resolution_minute):\n",
    "    '''\n",
    "    This function takes in the start and end datetime as well as the required resolution, and returns a dataframe that contains the API call with links to the traffic images\n",
    "    '''\n",
    "    # calculate number of observations required:\n",
    "    num_obs = (end_datetime - start_datetime) / datetime.timedelta(minutes=resolution_minute)\n",
    "    num_obs = int(np.floor(num_obs)) # converting the num_obst to an integer\n",
    "    \n",
    "    # create a list of datetime to be called inside the API\n",
    "    datetime_list = [start_datetime + datetime.timedelta(minutes=resolution_minute*x) for x in range(num_obs)]\n",
    "    \n",
    "    # convert the datetime list into a tqdm for displaying progress bar\n",
    "    datetime_list_pbar = tqdm(datetime_list)\n",
    "    \n",
    "    # insantiating a dictionary to contain the API calls\n",
    "    output_dict = {}\n",
    "    \n",
    "    # iterating through all the datetime_call from the datetime_list above and calling the api for each of the datetime_call\n",
    "    for datetime_call in datetime_list_pbar:\n",
    "        \n",
    "        # printing out current datetime_call\n",
    "        datetime_list_pbar.set_description(f'Currently scraping: {datetime_call.strftime(\"%Y-%m-%d_%H:%M\")}')\n",
    "\n",
    "        # actual API call\n",
    "        current_output = get_lta_traffic_camera_data(datetime_call) # calling the api on the specified datetime_call\n",
    "        output_dict[datetime_call.strftime(\"%Y-%m-%d_%H:%M\")] = current_output # appending the output dictionary with the current API call\n",
    "        \n",
    "    # CONVERTING THE DICTIONARY TO A DATAFRAME\n",
    "    # converting the output_dict to a long dataframe\n",
    "    output_df = pd.concat(output_dict.values(), axis=0)\n",
    "    \n",
    "    # filtering the columns of the df\n",
    "    output_df = output_df[['timestamp','image','camera_id','md5']]\n",
    "    \n",
    "    # removign the image link prefix (same for all images) in order to save space\n",
    "    image_link_prefix='https://images.data.gov.sg/api/traffic-images/'\n",
    "    output_df['image'] = output_df['image'].str.replace(image_link_prefix,'',regex=False)\n",
    "    \n",
    "    # returns the dataframe\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c7487-bcd1-4dfb-aa61-361d26b8793c",
   "metadata": {},
   "source": [
    "# Scraping Image Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd99962-1605-4432-beed-c21092605f97",
   "metadata": {},
   "source": [
    "We first need to scrape the image links from the data.gov.sg API. The actual images will be downloaded in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155decb7-a300-441d-b21d-53b482c77294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently scraping: 2022-10-01_00:55: 100%|████████████████████████████████████████████| 12/12 [00:03<00:00,  3.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# for this example, we will only be scraping the data for 1 hour on 01/10/2022\n",
    "# the actualdata required for scraping has already been obtained and scraped beforehand\n",
    "\n",
    "# DEFINING THE PARAMETERS FOR SCRAPING\n",
    "start_datetime = datetime.datetime(2022,10,1,0,0,0)\n",
    "end_datetime = datetime.datetime(2022,10,1,1,0,0)\n",
    "resolution_minute = 5\n",
    "\n",
    "df = lta_traffic_camera_scraping(start_datetime=start_datetime,\n",
    "                                 end_datetime=end_datetime,\n",
    "                                 resolution_minute=resolution_minute,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48482bd9-2412-466d-a457-f862d969a270",
   "metadata": {},
   "source": [
    "# Saving Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0f80cbb-be83-487c-89d3-e5b01ded7e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the filename for saving the file\n",
    "filename = 'LTA_traffic_cam_' + start_datetime.strftime('%Y%m%d') + '-' + end_datetime.strftime('%Y%m%d') + '.csv'\n",
    "\n",
    "# saving the data\n",
    "df.to_csv(f'../data/{filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
